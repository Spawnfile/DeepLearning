{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# CON2D OUTPUT SHAPE CALCULATION = [(input_shape - filter_size + 2*Padding)/stride] + 1.\n",
    "# if result of this value above is NOT a integer value, you will rounded to it's floor value. for instance 2.5 => 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor = torch.tensor([[1,2,3], [4,5,6]], dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device) # cuda:0 means you working on your first GPU that has CUDA.\n",
    "print(tensor.requires_grad)"
   ]
  },
  {
   "source": [
    "### Other Inıt Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_tensor = torch.empty(size = (3,3)) # hafızada yer tutmayan istenen şekillerde random bir tensor olusturur, np.zeros ile karıstırılmamalıdır! 0 içeren bir tensor olusturmaz.\n",
    "empty_tensor\n",
    "\n",
    "zero_tensor = torch.zeros((3, 3)) # istenen şekilde 0 içeren tensor \n",
    "zero_tensor\n",
    "\n",
    "rand_tensor = torch.rand((3, 3)) # istenen şekilde random değer içeren tensor. [0,1) arasında değerler üretir.\n",
    "rand_tensor\n",
    "\n",
    "rand_tensor = torch.randn((3, 3)) # istenen şekilde random değer içeren tensor ortalaması 0, varyansı 1 olan değerler üretir, bu yüzden negatif değer üretebilir.\n",
    "randn_tensor\n",
    "\n",
    "ones_tensor = torch.ones((3, 3))\n",
    "ones_tensor\n",
    "\n",
    "eye_tensor = torch.eye(5, 5)\n",
    "eye_tensor\n",
    "\n",
    "arange = torch.arange(start=0, end=5, step=1)\n",
    "arange\n",
    "\n",
    "linspace = torch.linspace(start=0.1, end=1, steps=10)\n",
    "linspace\n",
    "\n",
    "x = torch.empty(size=(1,5)).normal_(mean=0, std=1) # verilen ortalama ve standart sapma parametrelerine göre istenen sekilde normal dağılımlı bir tensor  \n",
    "x\n",
    "\n",
    "x = torch.empty(size=(1,5)).uniform_(0,1)\n",
    "x\n",
    "\n",
    "x = torch.diag(torch.ones(3)) # diagonal matrix oluşturur\n",
    "x"
   ]
  },
  {
   "source": [
    "### Convert Tensor Types"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.arange(4)\n",
    "print(tensor.dtype)\n",
    "print(tensor.bool())  # ilk deger 0 oldugu için false verir, geri kalan True\n",
    "\n",
    "print(tensor.short().dtype) # int16\n",
    "print(tensor.long().dtype) # int64\n",
    "print(tensor.half().dtype) # float16\n",
    "print(tensor.float().dtype) # float32\n",
    "print(tensor.double().dtype) # float 64"
   ]
  },
  {
   "source": [
    "### Array to Tensor or vide-versa convertion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np_array = np.zeros((3,3))\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)\n",
    "np_array_back = tensor.numpy()\n",
    "print(np_array_back)"
   ]
  },
  {
   "source": [
    "## Tensor Math operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([9,8,7])\n",
    "\n",
    "# Toplama\n",
    "z1 = torch.empty(3)\n",
    "torch.add(x, y, out=z1)\n",
    "print(z1)\n",
    "print(z1.dtype)\n",
    "\n",
    "z2 = torch.add(x, y)\n",
    "print(z2)\n",
    "print(z2.dtype)\n",
    "\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.dtype)\n",
    "\n",
    "# Çıkarma\n",
    "z = x - y\n",
    "print(z)\n",
    "print(z.dtype)\n",
    "\n",
    "# Bölme\n",
    "z = torch.true_divide(x, y) # element-wise division\n",
    "print(z)\n",
    "z = x / y\n",
    "print(z)\n",
    "\n",
    "# Inplace ops.\n",
    "t = torch.zeros(3)\n",
    "print(t)\n",
    "t.add_(x) # PYTORCH İÇİNDE ..._ ŞEKLİNDE YAZILAN OPERATİONSLAR INPLACE'DİR. YANİ FARKLI BİR KOPYA OLUSTURMADAN DİREK O DEĞİŞKENİN DEĞERİNİ DEĞİŞTİRİRLER.\n",
    "# add_() fonksiyonu, add() fonksiyonunu inplace olanıdır.\n",
    "print(t)\n",
    "\n",
    "# Kuvvet alma\n",
    "z = x.pow(2)\n",
    "print(z)\n",
    "z = x ** 2\n",
    "print(z)\n",
    "\n",
    "# karşılaştırma işlemleri\n",
    "z = x > 0\n",
    "print(z)\n",
    "\n",
    "z = x < 0\n",
    "print(z)\n",
    "\n",
    "# matrix çarpımı\n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "\n",
    "x3 = torch.mm(x1, x2) #2x3 output shape\n",
    "print(x3)\n",
    "\n",
    "x3 = x1.mm(x2) #2x3 output shape\n",
    "print(x3)\n",
    "\n",
    "# matris kuvveti alma\n",
    "\n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(matrix_exp.matrix_power(3))\n",
    "\n",
    "# element wise çarpım\n",
    "z = x * y\n",
    "print(z)\n",
    "\n",
    "# dot product\n",
    "z = torch.dot(x, y) # elemnt wise olarak carpım yapar ve cıkan sonucları toplar\n",
    "print(z)\n",
    "\n",
    "# BATCH MATRIX MULTIPLICATION\n",
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "\n",
    "tensor1 = torch.rand((batch, n, m))\n",
    "tensor2 = torch.rand((batch, m, p))\n",
    "\n",
    "out_bmm = torch.bmm(tensor1, tensor2)\n",
    "out_bmm.shape # (batch, n, p)\n"
   ]
  },
  {
   "source": [
    "## Broadcasting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand((5, 5))\n",
    "x2 = torch.rand((1, 5)) # bu matrix x1 ile cıkarma işlemine sokulabilmesi için onun shape'ine çevrilir. Yani 1x5 lik satır degeri 5x5 lik haline gelmiş gibi işlem yapılır. \n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "\n",
    "z = x1 - x2\n",
    "print(z)\n",
    "\n",
    "z = x1 ** x2 # element wise olarak x1^^x2 yapılır. shape olarak da yine yukarıdaki işlemin aynısı gerçeklenir\n",
    "print(z)"
   ]
  },
  {
   "source": [
    "## Other Tensor Ops."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_x = torch.sum(x, dim=0) # dim=0 yatay(y ekseni), dim=1 dikey(x ekseni)\n",
    "print(sum_x)\n",
    "\n",
    "values, indices = torch.max(x, dim=0)\n",
    "print(values, indices)\n",
    "\n",
    "values, indices = torch.min(x, dim=0)\n",
    "print(values, indices)\n",
    "\n",
    "abs_x = torch.abs(x) # mutlak deger işlemi\n",
    "\n",
    "z = torch.argmax(x, dim=0) # bu işlem torch.max ile aynı işlemi yapar fakat FARKI sadece max degerdeki tensorun SADECE İNDİS DEGERINI DÖNDÜRMESİDİR\n",
    "print(z)\n",
    "\n",
    "z = torch.argmin(x, dim=0) # bu fonksiyonlar x.min(dim=0) şeklinde de kullanılabilir.\n",
    "print(z)\n",
    "\n",
    "mean_x = torch.mean(x.float(), dim=0)  # mean hesabı için pytorch FLOAT DEGER İSTİYOR\n",
    "print(mean_x)\n",
    "\n",
    "z = torch.eq(x, y) # iki tensörün degerlernin eşit olup olmamasını karşılaştrır. Eşit ise True, değilse False return eder\n",
    "print(z)\n",
    "\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
    "print(sorted_y, indices)\n",
    "\n",
    "z = torch.clamp(x, min=0, max=10) # 0 dan az olan x degerlerinin 0 yapar, 10 dan büyük olan degerleri de 10 yapar. \n",
    "print(z)\n",
    "\n",
    "bool_tensor_ = torch.tensor([1,0,1,1,1], dtype=torch.bool)\n",
    "print(x)\n",
    "z = torch.any(bool_tensor_) # bool_tensor_ içinde hiç True degeri var mı ?\n",
    "print(z)\n",
    "z = torch.all(bool_tensor_) # bool_tensor_ içindeki bütün degeler True mu ? \n",
    "print(z)"
   ]
  },
  {
   "source": [
    "## Tensor Indexing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size, features))\n",
    "\n",
    "print(len(x)) # batch sayısı\n",
    "print(x[0].shape) # 10 tane tensorden ilkini alıyor ve onun shape'ini return ediyor. ---> x[0,:]\n",
    "\n",
    "print(x[:, 0]) # 10 tane tensorün teker teker hepsinin features degernini alıyor\n",
    "\n",
    "print(x[2, 0:10]) # 0:10 -->[0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# fancy indexing\n",
    "x = torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])\n",
    "\n",
    "x = torch.rand((3, 5))\n",
    "print(x)\n",
    "rows = torch.tensor([1, 0]) # x tensoörü üzerinden [1,4] ve [0,0] elemanlarını alır.\n",
    "cols = torch.tensor([4, 0])\n",
    "\n",
    "print(x[rows, cols])\n",
    "\n",
    "# more advanced indexing\n",
    "x = torch.arange(10)\n",
    "print(x)\n",
    "print(x[(x < 2) | (x > 8)]) # | == or. or kullanımı kabul edilimyor.\n",
    "print(x[x.remainder(2) == 0]) # remainder fonksiyonu mod alma işlemidir. element wise olarak çalışır. Bölümden sonra kalan değeri return eder.\n",
    "\n",
    "# useful operations\n",
    "print(torch.where(x > 5, x, x*2)) # x elementleri 5 ten büyükse x degerlerini yaz, büyük degilse 2 ile carpıp yaz. (condition, conditionTrue, conditionFalse)\n",
    "\n",
    "print(torch.tensor([0,0,1,2,2,3,4]).unique()) # tensor içindeki unique (tek sefer geçen) degerleri alır\n",
    "print(x.ndimension()) # x'te kac tane dimension oldugunu söyler. x = 5x5x5 tensor olsaydı return edilen dimension degeri 3 olacaktı\n",
    "print(x.numel()) # tensordeki element sayısını sayar"
   ]
  },
  {
   "source": [
    "## Tensor Reshaping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])\ntensor([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])\ntensor([[0, 3, 6],\n        [1, 4, 7],\n        [2, 5, 8]])\ntensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\ntensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\ntensor([[0.4247, 0.1286, 0.4273, 0.9628, 0.4274],\n        [0.9858, 0.5990, 0.3498, 0.1769, 0.5491],\n        [0.2531, 0.6928, 0.4505, 0.7693, 0.4993],\n        [0.0584, 0.8086, 0.3179, 0.7064, 0.5459]])\ntensor([[0.4247, 0.1286, 0.4273, 0.9628, 0.4274, 0.2531, 0.6928, 0.4505, 0.7693,\n         0.4993],\n        [0.9858, 0.5990, 0.3498, 0.1769, 0.5491, 0.0584, 0.8086, 0.3179, 0.7064,\n         0.5459]])\ntensor([0.4247, 0.1286, 0.4273, 0.9628, 0.4274, 0.9858, 0.5990, 0.3498, 0.1769,\n        0.5491])\ntorch.Size([64, 10])\ntorch.Size([64, 5, 2])\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\ntorch.Size([3, 3])\ntensor([[[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]])\ntorch.Size([1, 3, 3])\ntensor([[[1., 1., 1.]],\n\n        [[1., 1., 1.]],\n\n        [[1., 1., 1.]]])\ntorch.Size([3, 1, 3])\ntensor([[[1.],\n         [1.],\n         [1.]],\n\n        [[1.],\n         [1.],\n         [1.]],\n\n        [[1.],\n         [1.],\n         [1.]]])\ntorch.Size([3, 3, 1])\ntensor([[[[[0., 0.]],\n\n          [[0., 0.]]]],\n\n\n\n        [[[[0., 0.]],\n\n          [[0., 0.]]]]])\ntorch.Size([2, 1, 2, 1, 2])\ntensor([[[[0., 0.]],\n\n         [[0., 0.]]],\n\n\n        [[[0., 0.]],\n\n         [[0., 0.]]]])\ntorch.Size([2, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9) \n",
    "x_3x3 = x.view(3, 3) # contiguous array istiyor.\n",
    "print(x_3x3)\n",
    "\n",
    "x_3x3 = x.reshape (3, 3) # contiguous array olmasa da çalışıyor.\n",
    "print(x_3x3)\n",
    "\n",
    "y = x_3x3.t() # transpose işlemi. satırlar sütun oluyor.\n",
    "print(y)\n",
    "# y.view(9) # hata veriyor\n",
    "print(y.reshape(9)) # hata vermiyor\n",
    "\n",
    "\"\"\"\n",
    "C komsuluk tipinde satırlar sırayla farklı memory adreslerinde tutulur. Örneğin [0,1,2], [3,4,5], [6,7,8] farklı memory adreslerinde tutulur.\n",
    "Bu kısımda view() işlemi yapmada sorun yoktur. Fakat transpose işleminden sonra ortaya cıkan matriste mevcut satırlar önceki memori adreste tutulan satırlardan\n",
    "farkklı oldugu için view() işlemi gerçekleştirilemez. Çnükü rtık bir komsuluk söz konusu degildir. Bu yüzden view() yerine reshape() kullanılır.\n",
    "\"\"\"\n",
    "\n",
    "# view işlemi kullanılmak isteniyorsa ise\n",
    "print(y.contiguous().view(9))\n",
    "\n",
    "\n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((2, 5))\n",
    "\n",
    "print(torch.cat((x1, x2), dim=0))\n",
    "print(torch.cat((x1, x2), dim=1))\n",
    "\n",
    "z = x1.view(-1) # flatten\n",
    "print(z)\n",
    "\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch, -1) # batch dimension'unun tut diğerlerini flatten yap !!!\n",
    "# print(z)\n",
    "print(z.shape)\n",
    "\n",
    "# batch degerini tutup (batch,2,5) shape'ini (batch,5,2) haline getirmek için ise;\n",
    "z = x.permute(0, 2, 1) # 0.dimensionu 0 olarak tutuyoruz, ikinci dimensionu orjinalde indeksi 2 olan 5 degerini getirdik, 3. dimension'a ise orjinal tensorde indeksi 1 olan 2 degeri getirilecek\n",
    "print(z.shape)\n",
    "\n",
    "x = torch.ones(3,3)\n",
    "print(x)\n",
    "print(x.shape) # 3 3\n",
    "\n",
    "print(x.unsqueeze(0)) # indeks ile belirtilen noktaya 1 ekler, böylece boyut ve tensörün şekli değişir\n",
    "print(x.unsqueeze(0).shape) # 1 3 3\n",
    "\n",
    "print(x.unsqueeze(1)) # indeks ile belirtilen noktaya 1 ekler, böylece boyut ve tensörün şekli değişir\n",
    "print(x.unsqueeze(1).shape) # 3 1 3\n",
    "\n",
    "print(x.unsqueeze(2)) # indeks ile belirtilen noktaya 1 ekler, böylece boyut ve tensörün şekli değişir\n",
    "print(x.unsqueeze(2).shape)\n",
    "\n",
    "\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(torch.squeeze(x, 0)) # tensör içindeki tüm 1 degerleri yok eder, böylece boyut ve tensörün şekli değişir. indeks verildiğinde ise, indeksin tuttugu deger 1 ise onu yok eder, 1 degilse işlem yapmaz.\n",
    "print(torch.squeeze(x, 0).size())\n",
    "\n",
    "print(torch.squeeze(x, 1))\n",
    "print(torch.squeeze(x, 1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}